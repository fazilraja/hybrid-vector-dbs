{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    print(\"Warning: Using placeholder Pinecone API key. Set your key.\")\n",
    "    \n",
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new index 'hybrid-search'\n",
      "{'dimension': 512,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'dotproduct',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "index_name = \"hybrid-search\"\n",
    "\n",
    "existing_indexes = pinecone.list_indexes()\n",
    "if index_name in existing_indexes:\n",
    "    print(f\"Index '{index_name}' already exists. Deleting index.\")\n",
    "    pinecone.delete_index(index_name)\n",
    "    time.sleep(3)\n",
    "\n",
    "print(f\"Creating new index '{index_name}'\")\n",
    "pinecone.create_index(name=index_name,\n",
    "                      dimension=512,\n",
    "                      metric='dotproduct',\n",
    "                      spec=ServerlessSpec(cloud='aws', region='us-east-1'))\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "print(index.describe_index_stats())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone_text.sparse import BM25Encoder\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 319.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pinecone_text.sparse.bm25_encoder.BM25Encoder at 0x147bd0e00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = BM25Encoder()\n",
    "\n",
    "train_df = pd.read_csv('../data/legal_test_500.csv')\n",
    "\n",
    "encoder.fit(train_df['case_text'].astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_embeddings_and_sparse_vectors(cases, sparse_encoder):\n",
    "    \"\"\"\n",
    "    Group cases into batches of 100 and embed them using OpenAI's embedding API.\n",
    "    Also encode the case_text using the sparse encoder.\n",
    "    \"\"\"\n",
    "    all_embeddings_and_sparse_vectors = []\n",
    "    print(\"Grouping embeddings and sparse vectors...\")\n",
    "    \n",
    "    texts_to_encode = [case['case_text'] for case in cases if isinstance(case.get('case_text'), str)]\n",
    "    case_ids_map = {case['case_id']: i for i, case in enumerate(cases) if isinstance(case.get('case_text'), str)}\n",
    "    \n",
    "    original_indices = [case_ids_map[case['case_id']] for case in cases if isinstance(case.get('case_text'), str)]\n",
    "   \n",
    "    if not texts_to_encode:\n",
    "       print(\"No texts to encode\")\n",
    "       return []\n",
    "   \n",
    "    # batch encode sparse vectors\n",
    "    sparse_values = sparse_encoder.encode_documents(texts_to_encode)\n",
    "    \n",
    "    sparse_map = {}\n",
    "    for i, original_index in enumerate(original_indices):\n",
    "        sparse_map[original_index] = sparse_values[i]\n",
    "        \n",
    "    for i, case in enumerate(cases):\n",
    "        case_id = case.get('case_id')\n",
    "        case_title = case.get('case_title')\n",
    "        case_text = case.get('case_text')\n",
    "        embeddings = case.get('embeddings')\n",
    "        \n",
    "        # If embeddings is a string, convert it to a list of floats\n",
    "        if isinstance(embeddings, str):\n",
    "            # Remove brackets and split by comma\n",
    "            embeddings = embeddings.strip('[]').split(',')\n",
    "            # Convert to float values\n",
    "            embeddings = [float(x.strip()) for x in embeddings]\n",
    "\n",
    "        # Skip if essential data is missing\n",
    "        if not all([case_id, case_title, case_text, embeddings]):\n",
    "            print(f\"Skipping case index {i} due to missing data.\")\n",
    "            continue\n",
    "\n",
    "        # Get the corresponding sparse values using the original index 'i'\n",
    "        sparse_values = sparse_map.get(i)\n",
    "        if sparse_values is None:\n",
    "             print(f\"Warning: Sparse vector not found for case index {i}, case_id {case_id}. Skipping.\")\n",
    "             continue\n",
    "\n",
    "\n",
    "        # Create the new dictionary with the required structure\n",
    "        new_case_dict = {\n",
    "            'id': str(case_id), # Pinecone ID must be string\n",
    "            'sparse_values': sparse_values,\n",
    "            'values': embeddings,\n",
    "            'metadata': {\n",
    "                'case_title': case_title,\n",
    "                'case_text': case_text\n",
    "            }\n",
    "        }\n",
    "        # Add the new dictionary to the list\n",
    "        all_embeddings_and_sparse_vectors.append(new_case_dict)\n",
    "\n",
    "    return all_embeddings_and_sparse_vectors\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'case_id': 'Case2', 'case_title': 'Black v Lipovac [1998] FCA 699 ; (1998) 217 ALR 386', 'case_text': 'The general principles governing the exercise of the\\ndiscretion to award indemnity costs after rejection by an\\nunsuccessful party of a so called Calderbank letter were set\\nout in the judgment of the Full Court in Black v Lipovac\\n[1998] FCA 699 ; (1998) 217 ALR 386. In summary those\\nprinciples are: 1. Mere refusal of a \"Calderbank offer\" does\\nnot itself warrant an order for indemnity costs. In this\\nconnection it may be noted that Jessup J in Dais Studio Pty\\nLtd v Bullet Creative Pty Ltd [2008] FCA 42 said that (at\\n[6]): if the rejection of such an offer is to ground a claim\\nfor indemnity costs, it must be by reason of some\\ncircumstance other than that the offer happened to comply\\nwith the Calderbank principle. 2. To obtain an order for\\nindemnity costs the offeror must show that the refusal to\\naccept it was unreasonable. 3. The reasonableness of the\\nconduct of the offeree is to be viewed in the light of the\\ncircumstances that existed when the offer was rejected.', 'embeddings': '[-0.008599691092967987, 0.03886782377958298, 0.11749356985092163, 0.06041572615504265, 0.014686696231365204, 0.0030435025691986084, -0.014260188676416874, 0.005706856958568096, -0.030615827068686485, 0.019508086144924164, 0.07625214010477066, -0.001724574132822454, 0.033527206629514694, -0.021214116364717484, 0.007584417704492807, 0.03261855989694595, 0.07039229571819305, 0.012563429772853851, -0.015901315957307816, 0.0546671487390995, 0.0012377991806715727, 0.07721641659736633, -0.04168648272752762, -0.011895853094756603, -0.02375461906194687, -0.04724962264299393, 0.048139724880456924, -0.01904449053108692, 0.08559822291135788, 0.009707683697342873, 0.07691971957683563, -0.013954215683043003, 0.0066757709719240665, -0.03451002761721611, -0.015882771462202072, 0.09516682475805283, 0.0004262178554199636, 0.04098181799054146, -0.05707784369587898, 0.026536189019680023, -0.04172356799244881, 0.0014139653649181128, -0.014325091615319252, 0.03180263191461563, 0.009202364832162857, 0.0017489129677414894, 0.02677726000547409, 0.006615503691136837, -0.009276540018618107, 0.06716567277908325, -0.012832315638661385, -0.020527996122837067, 0.036049164831638336, 0.016763603314757347, 0.020361101254820824, 0.021826062351465225, -0.05418500676751137, 0.05737454444169998, 0.06605304777622223, -0.019878963008522987, -0.09064213186502457, 0.06238137185573578, 0.052108101546764374, -0.031227773055434227, -0.027852799743413925, 0.03647566959261894, 0.0019830286037176847, 0.12068310379981995, 0.045840293169021606, 0.039609573781490326, -0.04717544838786125, -0.006420793477445841, 0.025887155905365944, -0.029670093208551407, -0.03751412406563759, -0.013870768249034882, 0.042724933475255966, -0.03745849430561066, 0.037050530314445496, 0.06000776216387749, 0.013676058501005173, -0.034176237881183624, -0.06809286773204803, 0.005553870461881161, 0.024051319807767868, -0.004202490672469139, -0.004401836544275284, 0.017820600420236588, -0.1040678545832634, -0.023198304697871208, 0.0006658385973423719, 0.014733055606484413, -0.02507122978568077, -0.018358370289206505, 0.009939481504261494, 0.014176741242408752, 0.008479156531393528, 0.022679077461361885, 0.06449536234140396, -0.003328613704070449, -0.028557464480400085, -0.06152835488319397, 0.003161719301715493, 0.059043485671281815, 0.09894976019859314, -0.012721052393317223, -0.05971106141805649, 0.022734709084033966, 0.031005248427391052, -0.04394882544875145, 0.008803673088550568, -0.0033147057984024286, -0.08181528002023697, 0.0561506524682045, 0.018469633534550667, 0.019100122153759003, -0.07224667817354202, -0.007941385731101036, -0.013036297634243965, -0.02983698807656765, -0.030022425577044487, 0.011181916110217571, 0.0179318618029356, -0.006949292030185461, -0.030560195446014404, -0.017013944685459137, -0.06586761027574539, -0.040054626762866974, -0.014631064608693123, -0.09761460870504379, 0.03653130307793617, -0.013129016384482384, 0.02039818838238716, -0.031672824174165726, -0.03491799160838127, 0.011237547732889652, 0.025831524282693863, 0.11252383142709732, -0.05132926255464554, -0.027315029874444008, 0.07640048861503601, 0.03521469235420227, 0.013212463818490505, 0.02998533844947815, -0.02872435934841633, 0.07354474067687988, -0.028650183230638504, -0.039349962025880814, -0.02546064928174019, -0.006972471717745066, -0.10681233555078506, -0.011858765035867691, -0.054370444267988205, 0.06512585282325745, 0.007436067331582308, 0.010560698807239532, -0.03371264412999153, -0.02154790610074997, -0.0011728958925232291, -0.012999209575355053, -0.10540300607681274, -0.023791706189513206, -0.008247358724474907, -0.010959390550851822, -0.03623460233211517, 0.024922877550125122, 0.00036508121411316097, 0.049141090363264084, -0.02822367660701275, 0.031079422682523727, -0.09546352177858353, 0.00967059563845396, -0.044319700449705124, -0.012498526833951473, 0.09843053668737411, -0.12394681572914124, 0.028446201235055923, 0.04587738215923309, 0.022475095465779305, -0.014371451921761036, -0.023087041452527046, -0.011497161351144314, 0.06568217277526855, -0.03827441856265068, -0.04042550176382065, 0.04406008869409561, -0.02290160395205021, 0.09865306317806244, -0.03632732108235359, 0.0667206197977066, 0.07576999813318253, -0.05941436067223549, 0.0546671487390995, 0.024922877550125122, -0.04680457338690758, 0.01872924715280533, -0.008326170034706593, 0.09983986616134644, -0.04413426294922829, -0.0021012453362345695, 0.03942413628101349, -0.08871357887983322, 0.10569971054792404, 0.06071242690086365, 0.014714512042701244, 0.06705441325902939, -0.07050356268882751, 0.050402071326971054, 0.05755998194217682, -0.029447566717863083, 0.05626191571354866, 0.00010879999899771065, 0.0015739056980237365, 0.051255084574222565, -0.0402771532535553, 0.004128315486013889, -0.036049164831638336, -0.024181125685572624, -0.009902393445372581, 0.01697685569524765, 0.06171379238367081, 0.024218212813138962, -0.05841299518942833, -0.017570259049534798, -0.0896778553724289, 0.07640048861503601, -0.08886192739009857, 0.018024582415819168, -0.021232660859823227, -0.05147761106491089, -0.006379070226103067, 0.054073743522167206, -0.012637604959309101, -0.07602961361408234, -0.06071242690086365, 0.0010755409020930529, -0.03139466792345047, -0.0676107257604599, -0.023717530071735382, -0.0036137246061116457, -0.004596546292304993, 0.0042650760151445866, -0.016698699444532394, -0.01963789388537407, 0.016745058819651604, -0.015882771462202072, 0.022938691079616547, 0.013305182568728924, -0.03927578777074814, 0.02234528958797455, -0.05511219799518585, 0.008766585029661655, 0.021010134369134903, 0.042613670229911804, -0.057485807687044144, -0.015567527152597904, 0.006263171322643757, -0.04580320790410042, 0.002693488262593746, -0.022067131474614143, -0.010106375440955162, -0.009091101586818695, -0.005836663767695427, 0.022326745092868805, -0.04736088588833809, -0.06423575431108475, -0.023828793317079544, -0.03590081259608269, -0.0070327394641935825, 0.05429627001285553, -0.047286711633205414, 0.049104005098342896, -0.03540012985467911, 0.08263120800256729, -0.0015797006199136376, -0.024088406935334206, 0.044987279921770096, -0.0549638494849205, -0.009016926400363445, -0.03059728443622589, -0.04365212470293045, -0.002855746541172266, -0.031209228560328484, -0.07810652256011963, 0.010857399553060532, -0.004172356799244881, 0.019452454522252083, 0.05885804817080498, 0.03931287303566933, -0.0364571288228035, -0.021788975223898888, -0.03582663834095001, 0.024403652176260948, -0.008238086476922035, 0.02004585601389408, 0.007264536805450916, -0.027315029874444008, -0.07309969514608383, 0.03495507687330246, 0.015956947579979897, -0.06034155189990997, 0.06920549273490906, -0.008043376728892326, 0.053814131766557693, -0.020861783996224403, 0.0050810035318136215, -0.02751901187002659, -0.01597549021244049, -0.030931072309613228, 0.019563717767596245, 0.005604865960776806, 0.016893409192562103, -0.0967245027422905, 0.016819234937429428, 0.03871947154402733, 0.0026448105927556753, 0.03788499906659126, -0.03886782377958298, -0.002846474526450038, -0.09568604826927185, 0.04220570623874664, -0.04617408290505409, 0.06794451177120209, -0.07072608172893524, 0.05726328119635582, -0.0006026737974025309, 0.026091137900948524, 0.003015686757862568, -0.019860418513417244, 0.03823733329772949, -0.07602961361408234, 0.0596739761531353, -0.0479172021150589, -0.035845182836055756, -0.035233236849308014, 0.010477251373231411, -0.016216561198234558, -0.0361604280769825, 0.0549638494849205, -0.0967245027422905, -0.0643841028213501, -0.04098181799054146, 0.02019420638680458, -0.017412636429071426, 0.041575219482183456, 0.026054050773382187, 0.013379357755184174, 0.028019694611430168, 0.017820600420236588, 0.028093868866562843, -0.06827830523252487, -0.03823733329772949, -0.027092503383755684, 0.029058147221803665, -0.006392978131771088, 0.014325091615319252, 0.04847351461648941, -0.1025843471288681, -0.051663048565387726, -0.02837202697992325, -0.00916527770459652, 0.07691971957683563, -0.027036871761083603, 0.013360814191401005, -0.0032034427858889103, 0.011599152348935604, -0.11066944897174835, 0.00846061296761036, 0.08359548449516296, 0.0702439472079277, 0.01122827548533678, 0.011450801976025105, -0.07766146957874298, -0.020861783996224403, -0.0013339952565729618, -0.017162295058369637, -0.0326371043920517, 0.08915863186120987, 0.022085675969719887, -0.08307626098394394, 0.056929491460323334, -0.09257069230079651, -0.04068511724472046, -0.03241457790136337, 0.07391562312841415, 0.03109796717762947, -0.03195098042488098, -0.0027398476377129555, 0.028501832857728004, -0.040907640010118484, 0.016707971692085266, 0.021529361605644226, -0.010634873993694782, 0.10673815757036209, -0.05433335900306702, -0.013416444882750511, 0.0979113057255745, 0.029855530709028244, 0.06193631887435913, 0.009698411449790001, -0.040165890008211136, 0.00956860464066267, -0.018506720662117004, -0.04828807711601257, 0.05385122075676918, 0.009958025068044662, -0.07150492817163467, 0.012693236581981182, -0.032525841146707535, -0.0057532163336873055, 0.0010709048947319388, -0.030727090314030647, 0.06067534163594246, -0.07005850970745087, -0.04454222694039345, -0.0031709913164377213, 0.03271127864718437, 0.02957737445831299, -0.014482714235782623, 0.07576999813318253, 0.0514405257999897, -0.028909796848893166, 0.030968159437179565, -0.025034140795469284, -0.015317185781896114, 0.012906490825116634, -0.06749945878982544, -0.028242219239473343, 0.003361065173521638, -0.06037864089012146, -0.024032775312662125, 0.0949442982673645, 0.05433335900306702, 0.02716667950153351, 0.023921512067317963, -0.006796305533498526, 0.030226407572627068, -0.07576999813318253, -0.035177603363990784, 0.010607058182358742, -0.07128240168094635, 0.0564473532140255, -0.001168259885162115, 0.005127362906932831, -0.0482139028608799, 0.04951196908950806, 0.020583627745509148, -0.00405645789578557, -0.028112413361668587, -0.05882095918059349, -0.03439876437187195, 0.019322648644447327, 0.01808021403849125, 0.0664239227771759, -0.02677726000547409, 0.034843817353248596, 0.05325781926512718, 0.039164524525403976, -0.06375361233949661, -0.01678214594721794, 0.06586761027574539, -0.007473154924809933, 0.041463956236839294, -0.0037458492442965508, -0.06208467110991478, -0.0008901028195396066, 0.02431093342602253, 0.02601696364581585, -0.028205132111907005, -0.03248875215649605, -0.03250729665160179, -0.002980917226523161, 0.03931287303566933, -0.034676920622587204, 0.009443433955311775, 0.007528786081820726, -0.010162007063627243, -0.11489743739366531, 0.005915475077927113, -0.09716955572366714, 0.02028692699968815, -0.02742629311978817, 0.04391173645853996, 0.00430679926648736, -0.018617983907461166, 0.032933805137872696, 0.014084022492170334, 0.02316121570765972, -0.056484438478946686, -0.04806555062532425, -0.05444462224841118, -0.07443484663963318, 0.023828793317079544, -0.019823331385850906, -0.049549054354429245, -0.04268784821033478, 0.013388630002737045, -0.015780780464410782, 0.025349386036396027, 0.021659167483448982, -0.02557191252708435, 0.04687874764204025, 0.011886580847203732, 0.006267807446420193, -0.044171351939439774, 0.05488967150449753, -0.008279810659587383, -0.0032567563466727734, 0.02340228669345379, 0.02622094564139843, -0.04654495790600777, 0.06924258172512054]'}\n"
     ]
    }
   ],
   "source": [
    "all_cases_with_embeddings_csv = pd.read_csv('../data/all_cases_embeddings.csv')\n",
    "\n",
    "# convert to dataframe\n",
    "all_cases_with_embeddings = all_cases_with_embeddings_csv.to_dict(orient='records')\n",
    "\n",
    "print(all_cases_with_embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping embeddings and sparse vectors...\n",
      "Prepared 997 vectors for upsert.\n"
     ]
    }
   ],
   "source": [
    "all_cases_embeddings_and_sparse_vectors = group_embeddings_and_sparse_vectors(all_cases_with_embeddings, encoder)\n",
    "print(f\"Prepared {len(all_cases_embeddings_and_sparse_vectors)} vectors for upsert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample data prepared for Pinecone:\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "| ID     | Case Title                        | Case Text                         | Sparse Values                     | Embeddings                        |\n",
      "+========+===================================+===================================+===================================+===================================+\n",
      "| Case1  | Alpine Hardwood (Aust) Pty Ltd... | Ordinarily that discretion wil... | {'indices': [2486146960, 18412... | [-0.008599691092967987, 0.0388... |\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "| Case2  | Black v Lipovac [1998] FCA 699... | The general principles governi... | {'indices': [1026658409, 31135... | [-0.008599691092967987, 0.0388... |\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "| Case3  | Colgate Palmolive Co v Cussons... | Ordinarily that discretion wil... | {'indices': [2486146960, 18412... | [-0.008599691092967987, 0.0388... |\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "| Case4  | Dais Studio Pty Ltd v Bullett ... | The general principles governi... | {'indices': [1026658409, 31135... | [-0.008599691092967987, 0.0388... |\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "| Case5  | Dr Martens Australia Pty Ltd v... | The preceding general principl... | {'indices': [1622038283, 10266... | [-0.008599691092967987, 0.0388... |\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "| Case6  | GEC Marconi Systems Pty Ltd v ... | I accept that the making of a ... | {'indices': [318824902, 337790... | [-0.008599691092967987, 0.0388... |\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "| Case7  | John S Hayes &amp; Associates ... | The preceding general principl... | {'indices': [1622038283, 10266... | [-0.008599691092967987, 0.0388... |\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "| Case8  | Seven Network Limited v News L... | On the question of the level o... | {'indices': [3997133275, 38054... | [-0.008599691092967987, 0.0388... |\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "| Case9  | Australian Broadcasting Corpor... | recent decision of the High Co... | {'indices': [569308866, 370490... | [-0.008599691092967987, 0.0388... |\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n",
      "| Case10 | Hexal Australia Pty Ltd v Roch... | Hexal Australia Pty Ltd v Roch... | {'indices': [4095315130, 24036... | [-0.008599691092967987, 0.0388... |\n",
      "+--------+-----------------------------------+-----------------------------------+-----------------------------------+-----------------------------------+\n"
     ]
    }
   ],
   "source": [
    "table_data = []\n",
    "for case in all_cases_embeddings_and_sparse_vectors[:10]:\n",
    "     table_data.append([\n",
    "        case['id'],\n",
    "        case['metadata']['case_title'][:30] + '...' if len(case['metadata']['case_title']) > 30 else case['metadata']['case_title'], # Truncate title\n",
    "        case['metadata']['case_text'][:30] + '...' if len(case['metadata']['case_text']) > 30 else case['metadata']['case_text'], # Truncate text\n",
    "        str(case['sparse_values'])[:30] + '...', # Show truncated sparse values\n",
    "        str(case['values'])[:30] + '...' # Show truncated dense values\n",
    "     ])\n",
    "\n",
    "# Define the headers based on the keys\n",
    "headers = [\"ID\", \"Case Title\", \"Case Text\", \"Sparse Values\", \"Embeddings\"]\n",
    "\n",
    "# Print the table\n",
    "# Presenter: So we got sparse values here and we got the embeddings.\n",
    "print(\"\\nSample data prepared for Pinecone:\")\n",
    "print(tabulate(table_data, headers=headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_upsert(index, vectors, batch_size=100):\n",
    "    print(f\"Upserting {len(vectors)} vectors in batches of {batch_size}...\")\n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        i_end = min(i + batch_size, len(vectors))\n",
    "        batch = vectors[i:i_end]\n",
    "        try:\n",
    "            index.upsert(vectors=batch)\n",
    "        except Exception as e:\n",
    "            print(f\"Error upserting batch {i // batch_size}: {e}\")\n",
    "    print(\"Upsert complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting 997 vectors in batches of 100...\n",
      "Upsert complete.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(index, all_cases_embeddings_and_sparse_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
