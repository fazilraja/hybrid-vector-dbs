{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "import pandas as pd\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.rerankers import RRFReranker\n",
    "import ast\n",
    "import pyarrow as pa\n",
    "import openai\n",
    "import os\n",
    "from lancedb.embeddings import EmbeddingFunction, EmbeddingFunctionConfig, get_registry, registry, EmbeddingFunctionRegistry\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    print(\"Warning: OpenAI API key not found. Set the OPENAI_API_KEY environment variable or set openai.api_key directly.\")\n",
    "\n",
    "uri = \"../data/sample-lancedb\"\n",
    "db = lancedb.connect(uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_NAME = \"cases_hybrid_search\"\n",
    "CSV_PATH = \"../data/all_cases_embeddings.csv\"\n",
    "TEXT_COLUMN = \"case_text\" # Column for FTS and potentially main text content\n",
    "VECTOR_COLUMN = \"vector\" # Name for the vector field in the schema\n",
    "EMBEDDING_DIM = 512\n",
    "\n",
    "# --- LanceDB Schema Definition ---\n",
    "# Define a schema that matches your CSV structure and includes the vector\n",
    "class CaseDocuments(LanceModel):\n",
    "    case_id: str\n",
    "    case_title: str\n",
    "    case_text: str\n",
    "    # Define the vector field with the correct dimensions.\n",
    "    # We don't need SourceField here as embeddings are pre-computed.\n",
    "    vector: Vector(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_embedding(embedding_str: str) -> list[float]:\n",
    "    \"\"\"Parses a string representation of a list into a list of floats.\"\"\"\n",
    "    try:\n",
    "        embedding_list = ast.literal_eval(embedding_str)\n",
    "        if isinstance(embedding_list, list) and all(isinstance(x, (int, float)) for x in embedding_list):\n",
    "            return [float(x) for x in embedding_list]\n",
    "        else:\n",
    "            print(f\"Warning: Could not parse embedding string correctly: {embedding_str[:100]}...\")\n",
    "            return [0.0] * EMBEDDING_DIM\n",
    "    except (ValueError, SyntaxError, TypeError) as e:\n",
    "        print(f\"Error parsing embedding string: {embedding_str[:100]}... Error: {e}\")\n",
    "        return [0.0] * EMBEDDING_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing embedding strings...\n",
      "Finished parsing embeddings.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "required_columns = ['case_id', 'case_title', 'case_text', 'embeddings']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    raise ValueError(f\"CSV missing one or more required columns: {required_columns}\")\n",
    "\n",
    "    # Handle potential NaN/missing values before parsing\n",
    "df['embeddings'] = df['embeddings'].fillna('[]')\n",
    "df['case_id'] = df['case_id'].fillna('UNKNOWN_ID').astype(str)\n",
    "df['case_title'] = df['case_title'].fillna('UNKNOWN_TITLE').astype(str)\n",
    "df['case_text'] = df['case_text'].fillna('').astype(str)\n",
    "\n",
    "\n",
    "# 3. Parse embedding strings into lists of floats\n",
    "print(\"Parsing embedding strings...\")\n",
    "# IMPORTANT: This assumes your 'embeddings' column contains strings like '[0.1, 0.2, ...]', which mine do since its a csv file\n",
    "df[VECTOR_COLUMN] = df['embeddings'].apply(parse_embedding)\n",
    "print(\"Finished parsing embeddings.\")\n",
    "\n",
    "# Verify embedding dimensions (optional but recommended)\n",
    "first_valid_vector = df[VECTOR_COLUMN].iloc[0] # Check the first one\n",
    "if len(first_valid_vector) != EMBEDDING_DIM:\n",
    "        print(f\"Warning: Parsed vector dimension ({len(first_valid_vector)}) does not match expected dimension ({EMBEDDING_DIM}). Check CSV format and parsing logic.\")\n",
    "\n",
    "# Select columns for LanceDB, renaming 'embeddings' if needed\n",
    "# We need columns matching the CaseDocuments schema\n",
    "lancedb_data = df[['case_id', 'case_title', 'case_text', VECTOR_COLUMN]].to_dict('records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating/Overwriting LanceDB table: cases_hybrid_search\n",
      "Table created successfully.\n",
      "Adding 997 records to the table...\n",
      "Data added successfully.\n"
     ]
    }
   ],
   "source": [
    "# 4. Create LanceDB Table\n",
    "print(f\"Creating/Overwriting LanceDB table: {TABLE_NAME}\")\n",
    "try:\n",
    "    # Use mode=\"overwrite\" to start fresh each time, or \"create\" to fail if exists\n",
    "    table = db.create_table(TABLE_NAME, schema=CaseDocuments, mode=\"overwrite\")\n",
    "    print(\"Table created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating LanceDB table: {e}\")\n",
    "\n",
    "# 5. Add data to the table\n",
    "print(f\"Adding {len(lancedb_data)} records to the table...\")\n",
    "try:\n",
    "    # LanceDB can infer schema from list of dicts, but explicit schema is safer\n",
    "    table.add(lancedb_data)\n",
    "    print(\"Data added successfully.\")\n",
    "except pa.ArrowInvalid as e:\n",
    "        print(f\"Error adding data to LanceDB table (potential schema mismatch or data type issue): {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding data to LanceDB table: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FTS index on column: case_text\n",
      "Error creating FTS index: Index already exists. Use replace=True to overwrite.\n"
     ]
    }
   ],
   "source": [
    "# 6. Create FTS index\n",
    "print(f\"Creating FTS index on column: {TEXT_COLUMN}\")\n",
    "try:\n",
    "    table.create_fts_index(TEXT_COLUMN)\n",
    "    print(\"FTS index creation initiated. It might take some time to build.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating FTS index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Hybrid Search Example ---\n",
      "Searching for: 'bankruptcy case'\n",
      "Embedding the search query using OpenAI...\n",
      "\n",
      "Hybrid search results:\n",
      "   case_id                                         case_title  \\\n",
      "0  Case514  Re Glew; Glew v Harrowell [2003] FCA 373 , 198...   \n",
      "1  Case516   Re Griffin, Ex parte Soutar (1890) 1 BC (NSW) 29   \n",
      "2  Case515       Re Gould; Ex parte Skinner (1983) 72 FLR 393   \n",
      "3  Case517                        Re Jocumsen (1929) 1 ABC 82   \n",
      "4  Case513  Re Gibbs; Ex parte Triscott (1995) 65 FCR 80 ,...   \n",
      "\n",
      "                                           case_text  \n",
      "0  To \" satisfy \" the Court it is not necessary f...  \n",
      "1  A claim for unliquidated damages for breach of...  \n",
      "2  Some decisions involving the application of s ...  \n",
      "3  The \" counter-claim, set-off or cross demand \"...  \n",
      "4  The \" final judgment or final order \" in the p...  \n"
     ]
    }
   ],
   "source": [
    "# --- Example Hybrid Search ---\n",
    "print(\"\\n--- Performing Hybrid Search Example ---\")\n",
    "# Create a reranker (Optional but recommended for hybrid search)\n",
    "reranker = RRFReranker()\n",
    "\n",
    "try:\n",
    "    search_query = \"bankruptcy case\" # Example query\n",
    "    print(f\"Searching for: '{search_query}'\")\n",
    "\n",
    "    print(\"Embedding the search query using OpenAI...\")\n",
    "    client = openai.OpenAI(api_key=openai.api_key)\n",
    "    \n",
    "    query_vector = client.embeddings.create(\n",
    "                        model=\"text-embedding-3-small\",\n",
    "                        input=search_query,\n",
    "                        dimensions=512\n",
    "                    ).data[0].embedding\n",
    "\n",
    "    # 3. Perform the search using the vector and the text query\n",
    "    results = (\n",
    "        table.search(query_type='hybrid')\n",
    "        .vector(query_vector)\n",
    "        .text(search_query)\n",
    "        .rerank(reranker=reranker)\n",
    "        .limit(5)\n",
    "        .to_pandas()\n",
    "    )\n",
    "\n",
    "    print(\"\\nHybrid search results:\")\n",
    "    print(results[['case_id', 'case_title', 'case_text']]) # Show relevant columns\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during search: {e}\")\n",
    "    # This could happen if the FTS index isn't ready yet or other issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
